{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.llms import Together\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = PyMuPDFLoader(\"../DocumentStore/msme-features.pdf\")\n",
    "# loader = PyMuPDFLoader(\"../DocumentStore/UMK-FInal updated User manual Create org-260424-093614.pdf\")\n",
    "loader = PyMuPDFLoader(\"../DocumentStore/FRDs-170424-070159.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, \n",
    "                                               chunk_overlap = 200, \n",
    "                                                length_function=len,\n",
    "                                                is_separator_regex=False,\n",
    "                                                separators=[\n",
    "                                                            \"\\n\\n\",\n",
    "                                                            \"\\n\",\n",
    "                                                            \".\",\n",
    "                                                            \",\",\n",
    "                                                            \"\\u200B\",  # Zero-width space\n",
    "                                                            \"\\uff0c\",  # Fullwidth comma\n",
    "                                                            \"\\u3001\",  # Ideographic comma\n",
    "                                                            \"\\uff0e\",  # Fullwidth full stop\n",
    "                                                            \"\\u3002\",  # Ideographic full stop\n",
    "                                                            \" \",\n",
    "                                                            \"\",\n",
    "                                                        ]\n",
    "                                            )\n",
    "splits = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\debgh\\AllProjects\\RAGProjects\\pdfBot\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=splits, embedding=embedding_function, persist_directory=\"../chroma_d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Bank Reconcilation Statement\"\n",
    "k = 10\n",
    "results = vectorstore.similarity_search_with_relevance_scores(query, k=k)\n",
    "# Print out just the video titles\n",
    "# [(r[0].metadata['title'], r[1]) for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Bank Reconcilation Statement\"\n",
    "k = 10\n",
    "results = vectorstore.similarity_search_with_relevance_scores(query, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\":k})\n",
    "query = \"How update MSME UDYAM details?\"\n",
    "results = retriever.invoke(query)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# print(results[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\debgh\\AllProjects\\RAGProjects\\pdfBot\\.venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `Together` was deprecated in LangChain 0.0.12 and will be removed in 0.2. An updated version of the class exists in the langchain-together package and should be used instead. To use it run `pip install -U langchain-together` and import as `from langchain_together import Together`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "prompt = PromptTemplate(input_variables=['context', 'question'],\n",
    "                        template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Keep answers descriptive and mention the process.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\")\n",
    "\n",
    "# model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "# response = Together(model=\"mistralai/Mixtral-8x22B-Instruct-v0.1\", \n",
    "#                     temperature = 0.3,\n",
    "#                     together_api_key= \"dc50d15b1bed2012efe79427bafd87b100c9bf0d20609c832c485aec433ddd7d\", \n",
    "#                     max_tokens = 2000)\n",
    "\n",
    "response = Together(\n",
    "        model=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "        together_api_key= \"dc50d15b1bed2012efe79427bafd87b100c9bf0d20609c832c485aec433ddd7d\",\n",
    "        temperature=0.3,\n",
    "        max_tokens=512\n",
    "    )\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever \n",
    "    | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | response\n",
    "    | StrOutputParser())\n",
    "# print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The functionality of Reconciliation statement: Missing in Books is to identify and report on missing transactions in the Bank Reconciliation Statement (BRS) process. It is a component of the BRS process that displays transactions with a \"Missing in Books\" status from the Bank Statement within a specified date range. The system dynamically searches and displays transactions matching the user's input and filters records based on voucher type. The section functions similarly to the Bank Statement screen within the BRS, excluding the \"Status\" column and offering a voucher type filter. The Reconciliation statement: Missing in Books section is a part of the BRS process that helps identify and report on missing transactions.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the functionality of Reconcilation statement:missing in books?\"\n",
    "\n",
    "query_list = [\"Describe the ledger statement data-table?\", ]\n",
    "# query = \"Summarise the document for me in 500 words\"\n",
    "ls = rag_chain.invoke(query)\n",
    "print(ls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
